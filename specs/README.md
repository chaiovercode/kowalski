# Kowalski Analytics Plugin - Technical Specification

> "Skipper, I've completed my analysis. The results are... concerning." - Kowalski

## 1. Overview

Kowalski is an intelligent data analytics plugin for Claude Code that combines the analytical rigor of a Senior Data Analyst at Stanford University (IQ 180) with the personality of Kowalski from Madagascar. It enables Claude to perform sophisticated exploratory data analysis, find relationships between datasets, and create interactive visualizations.

### 1.1 Core Philosophy

Kowalski approaches data like a seasoned researcher:
- **Hypothesis-driven**: Forms and tests hypotheses about data relationships
- **Skeptical**: Questions data quality, detects synthetic/fake data, validates assumptions
- **Rigorous**: Uses proper statistical methods (Pearson correlation, IQR outlier detection, linear regression)
- **Communicative**: Expresses uncertainty with confidence levels, asks clarifying questions when confused

### 1.2 Personality Guidelines

All user-facing messages should embody Kowalski's character:
- Uses military/scientific jargon ("recon sweep", "intel", "mission parameters")
- Addresses the user as "Skipper"
- Expresses analytical findings with dramatic flair
- Shows uncertainty: "73% confident this is a date column, Skipper. Shall I proceed?"
- Celebrates discoveries: "Eureka! Strong correlation detected in sector 7!"

---

## 2. System Architecture

### 2.1 High-Level Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         Claude Code Environment                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                          â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚   â”‚  /kowalski   â”‚â”€â”€â”€â”€â–¶â”‚           Kowalski Skill Engine              â”‚  â”‚
â”‚   â”‚   Command    â”‚     â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚  â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚  â”‚         Analysis Brain                  â”‚ â”‚  â”‚
â”‚                        â”‚  â”‚  - Stanford-level statistical rigor     â”‚ â”‚  â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚  â”‚  - Hypothesis generation & testing      â”‚ â”‚  â”‚
â”‚   â”‚    Memory    â”‚â—€â”€â”€â”€â–¶â”‚  â”‚  - Uncertainty quantification           â”‚ â”‚  â”‚
â”‚   â”‚   (CLAUDE.md â”‚     â”‚  â”‚  - Relationship discovery               â”‚ â”‚  â”‚
â”‚   â”‚   + project) â”‚     â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚  â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚                      â”‚                       â”‚  â”‚
â”‚                        â”‚                      â–¼                       â”‚  â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚  â”‚
â”‚   â”‚ Data Sources â”‚â”€â”€â”€â”€â–¶â”‚  â”‚         Data Understanding              â”‚ â”‚  â”‚
â”‚   â”‚  - CSV/JSON  â”‚     â”‚  â”‚  - Schema inference                     â”‚ â”‚  â”‚
â”‚   â”‚  - MCPs      â”‚     â”‚  â”‚  - Column semantics detection           â”‚ â”‚  â”‚
â”‚   â”‚  - APIs      â”‚     â”‚  â”‚  - Relationship mapping                 â”‚ â”‚  â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚  â”‚  - Clarifying questions                 â”‚ â”‚  â”‚
â”‚                        â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚  â”‚
â”‚                        â”‚                      â”‚                       â”‚  â”‚
â”‚                        â”‚                      â–¼                       â”‚  â”‚
â”‚                        â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚  â”‚
â”‚                        â”‚  â”‚      Visualization Engine               â”‚ â”‚  â”‚
â”‚                        â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”‚  â”‚
â”‚                        â”‚  â”‚  â”‚ Terminal Viz â”‚  â”‚   Browser Viz    â”‚ â”‚ â”‚  â”‚
â”‚                        â”‚  â”‚  â”‚ (Ink/Braille)â”‚  â”‚   (Recharts)     â”‚ â”‚ â”‚  â”‚
â”‚                        â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚  â”‚
â”‚                        â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚  â”‚
â”‚                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                           â”‚                             â”‚
â”‚                                           â–¼                             â”‚
â”‚                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚                        â”‚              Tmux Split Pane                 â”‚  â”‚
â”‚                        â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚  â”‚
â”‚                        â”‚  â”‚         Interactive Dashboard           â”‚ â”‚  â”‚
â”‚                        â”‚  â”‚  - Filter data                          â”‚ â”‚  â”‚
â”‚                        â”‚  â”‚  - Drill into columns                   â”‚ â”‚  â”‚
â”‚                        â”‚  â”‚  - Change chart types                   â”‚ â”‚  â”‚
â”‚                        â”‚  â”‚  - Export / Save                        â”‚ â”‚  â”‚
â”‚                        â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚  â”‚
â”‚                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2.2 Component Overview

| Component | Purpose | Location |
|-----------|---------|----------|
| Skill Entry | `/kowalski` command handler | `src/skills/kowalski/` |
| Analysis Brain | Statistical analysis with Stanford rigor | `src/canvases/analytics/brain.ts` |
| Data Understanding | Schema inference, relationship discovery | `src/canvases/analytics/understanding.ts` |
| Memory Manager | Cross-session persistence | `src/canvases/analytics/memory.ts` |
| Terminal Viz | Ink-based interactive dashboard | `src/canvases/analytics/components/` |
| Browser Viz | Recharts-based HTML visualizations | `src/canvases/analytics/browser/` |
| IPC Layer | Communication between Claude and canvas | `src/ipc/` (existing) |

---

## 3. Functional Requirements

### 3.1 Data Sources

#### 3.1.1 CSV/JSON Files (REF: DS-001)
- Parse CSV files with robust quote handling (existing: `data-loader.ts`)
- Parse JSON files (arrays of objects)
- Auto-detect delimiters (comma, tab, semicolon)
- Handle common encodings (UTF-8, Latin-1)
- Support large files up to 100k rows with automatic sampling

#### 3.1.2 MCP Integration (REF: DS-002)
- Query MCP servers directly for data
- Accept data provided by user from MCP queries
- Support common data MCP patterns (databases, APIs)

#### 3.1.3 API Integration (REF: DS-003)
- Fetch data from REST APIs (JSON responses)
- Handle pagination for large datasets
- Support authentication (Bearer tokens, API keys via env vars)

### 3.2 Data Understanding

#### 3.2.1 Schema Inference (REF: DU-001)
- Infer column types: numeric, categorical, date, text, ID, boolean
- Detect semantic meaning: percentage, currency, count, rate
- Confidence scoring for each inference (0-100%)

#### 3.2.2 Relationship Discovery (REF: DU-002)
- Detect foreign key relationships between tables
- Identify join columns (exact match, fuzzy match)
- Map one-to-one, one-to-many, many-to-many relationships
- Calculate relationship strength confidence

#### 3.2.3 Clarifying Questions (REF: DU-003)
When Kowalski doesn't understand:
- Ambiguous column names: "Skipper, column 'val' could be value, validation, or valley. Which is it?"
- Unknown relationships: "I see 'customer_id' in both tables. Is this a linking field?"
- Mixed data types: "Column 'amount' has 73% numbers and 27% text. Should I treat as numeric?"
- Unusual patterns: "82% of rows have 'status=3'. Is this expected or data quality issue?"

### 3.3 Analysis Capabilities

#### 3.3.1 Exploratory Data Analysis (REF: AN-001)
Based on existing `insights.ts` and `stats.ts`:
- Descriptive statistics (mean, median, std, percentiles)
- Distribution analysis (histograms, box plots)
- Missing value analysis
- Synthetic data detection

#### 3.3.2 Correlation Analysis (REF: AN-002)
- Pearson correlation for numeric pairs
- CramÃ©r's V for categorical pairs
- Point-biserial for numeric-categorical pairs
- Correlation heatmap generation

#### 3.3.3 Trend Detection (REF: AN-003)
- Linear regression for time series
- Seasonality detection
- Change point detection
- Growth rate calculation

#### 3.3.4 Outlier Detection (REF: AN-004)
- IQR method (existing)
- Z-score method
- Isolation Forest for multivariate outliers
- Contextual outliers (within groups)

#### 3.3.5 Hypothesis Generation (REF: AN-005)
Stanford-level analytical thinking:
- Generate testable hypotheses from patterns
- Suggest causal vs correlational interpretations
- Identify confounding variables
- Recommend follow-up analyses

### 3.4 Memory System

#### 3.4.1 What to Remember (REF: MEM-001)
Stored in summarized form in CLAUDE.md / project notes:

```markdown
## Kowalski Intel

### Known Datasets
- `sales.csv`: 2,847 rows, columns: date, product_id, revenue, quantity
  - Relationships: product_id â†’ products.csv.id
  - Notes: Revenue is in USD, dates are US format

### Column Semantics
- `status` values: 1=pending, 2=shipped, 3=delivered, 4=returned
- `region_code`: Maps to geographic regions (see regions.csv)

### User Preferences
- Preferred chart type: bar charts
- Color scheme: dark mode
- Export format: PNG

### Previous Findings
- Strong correlation (r=0.87) between marketing_spend and revenue
- Seasonality detected in sales data (Q4 spike)
```

#### 3.4.2 Memory Retrieval (REF: MEM-002)
- Load relevant memory when dataset is loaded
- Match by filename, column names, and data patterns
- Surface relevant past findings: "Ah, I recognize this dataset from Operation Delta..."

### 3.5 Visualization

#### 3.5.1 Terminal Visualization (REF: VIZ-001)
Using existing Ink infrastructure:
- Braille-based charts (high resolution)
- Interactive filtering (keyboard navigation)
- Drill-down into specific data points
- Real-time updates via IPC

#### 3.5.2 Browser Visualization (REF: VIZ-002)
New Recharts-based system:
- Line charts, bar charts, scatter plots, pie charts
- Interactive tooltips and zoom
- Responsive layout
- Auto-open in default browser

#### 3.5.3 Export Options (REF: VIZ-003)
- PNG image export
- SVG vector export
- CSV data export (filtered/transformed data)
- JSON analysis results export

### 3.6 Interactive Features

#### 3.6.1 Dashboard Interactions (REF: INT-001)
In the tmux split pane:
- **Filter**: Apply column filters (numeric ranges, categorical selection)
- **Drill-down**: Click on data point to see details
- **Chart switching**: Toggle between chart types
- **Column selection**: Choose which columns to visualize

#### 3.6.2 Live Updates (REF: INT-002)
- Dashboard updates when Claude sends new analysis
- User can also trigger updates: "Update the dashboard"
- IPC messages for real-time sync

---

## 4. Non-Functional Requirements

### 4.1 Performance

#### 4.1.1 Dataset Size Tiers (REF: PERF-001)
| Size | Rows | Behavior |
|------|------|----------|
| Small | < 10,000 | Full analysis, no sampling |
| Medium | 10,000 - 100,000 | Smart sampling for viz, full data for aggregations |
| Large | > 100,000 | Warn user, require confirmation, chunked processing |

#### 4.1.2 Response Times (REF: PERF-002)
- Initial scan: < 2 seconds for datasets up to 50k rows
- EDA report generation: < 5 seconds
- Chart rendering: < 1 second
- Filter application: < 500ms

### 4.2 Reliability

#### 4.2.1 Error Handling (REF: REL-001)
- Graceful handling of malformed CSV/JSON
- Clear error messages in Kowalski voice
- Recovery suggestions: "Data appears corrupted at row 1,247. Shall I skip and continue?"

#### 4.2.2 State Persistence (REF: REL-002)
- Canvas state survives brief disconnections
- Analysis can be resumed after interruption
- Memory persists across Claude Code sessions

### 4.3 Usability

#### 4.3.1 Onboarding (REF: USE-001)
When `/kowalski` invoked with no args:
1. Recon sweep of current directory
2. List detected data files with row counts
3. Show previous mission context
4. Prompt for orders

#### 4.3.2 Uncertainty Communication (REF: USE-002)
Express confidence levels:
- "I'm 95% certain this is a date column"
- "Low confidence (42%) on the relationship between these tables"
- "This correlation (r=0.34) is statistically significant but weak"

---

## 5. Technical Design

### 5.1 Skill Registration

```typescript
// src/skills/kowalski/index.ts
export const kowalskiSkill: Skill = {
  name: "kowalski",
  description: "Kowalski Analytics - Data analysis with military precision",
  command: "/kowalski",
  handler: kowalskiHandler,
};
```

### 5.2 Entry Point Flow

```
/kowalski [command] [args]

Commands:
  (no args)     - Recon sweep, show status, await orders
  analyze <file>- Load and analyze specified file
  compare <f1> <f2> - Find relationships between files
  query <mcp>   - Fetch data from MCP server
  memory        - Show/manage Kowalski's memory
  dashboard     - Open interactive dashboard
  help          - Mission briefing (help text)
```

### 5.3 Analysis Brain Interface

```typescript
// src/canvases/analytics/brain.ts
interface AnalysisBrain {
  // Core analysis
  analyze(data: DataSet): Promise<AnalysisResult>;

  // Understanding
  inferSchema(data: DataSet): Promise<SchemaInference>;
  findRelationships(datasets: DataSet[]): Promise<Relationship[]>;

  // Hypothesis
  generateHypotheses(analysis: AnalysisResult): Hypothesis[];
  testHypothesis(data: DataSet, hypothesis: Hypothesis): HypothesisResult;

  // Uncertainty
  getConfidenceLevel(inference: Inference): number;
  generateClarifyingQuestions(issues: InferenceIssue[]): Question[];
}
```

### 5.4 Memory Manager Interface

```typescript
// src/canvases/analytics/memory.ts
interface KowalskiMemory {
  // Dataset intel
  rememberDataset(dataset: DatasetMemo): void;
  recallDataset(identifier: DatasetIdentifier): DatasetMemo | null;

  // Column semantics
  rememberColumnMeaning(column: ColumnMemo): void;
  recallColumnMeaning(columnName: string): ColumnMemo | null;

  // User preferences
  getPreferences(): UserPreferences;
  updatePreferences(prefs: Partial<UserPreferences>): void;

  // Findings
  recordFinding(finding: AnalysisFinding): void;
  recallFindings(datasetId: string): AnalysisFinding[];

  // Persistence
  save(): Promise<void>;  // Write to CLAUDE.md
  load(): Promise<void>;  // Read from CLAUDE.md
}
```

### 5.5 Data Understanding Pipeline

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Data Understanding Pipeline                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚   Load      â”‚â”€â”€â”€â–¶â”‚   Infer     â”‚â”€â”€â”€â–¶â”‚  Validate   â”‚â”€â”€â”€â–¶â”‚  Report   â”‚ â”‚
â”‚  â”‚   Data      â”‚    â”‚   Schema    â”‚    â”‚  & Question â”‚    â”‚  Finding  â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚        â”‚                  â”‚                   â”‚                  â”‚       â”‚
â”‚        â–¼                  â–¼                   â–¼                  â–¼       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ - Parse CSV â”‚    â”‚ - Type      â”‚    â”‚ - Check     â”‚    â”‚ - EDA     â”‚ â”‚
â”‚  â”‚ - Parse JSONâ”‚    â”‚   detection â”‚    â”‚   memory    â”‚    â”‚   Report  â”‚ â”‚
â”‚  â”‚ - Fetch API â”‚    â”‚ - Semantic  â”‚    â”‚ - Generate  â”‚    â”‚ - Hypo-   â”‚ â”‚
â”‚  â”‚ - Query MCP â”‚    â”‚   inference â”‚    â”‚   questions â”‚    â”‚   theses  â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚ - Confidenceâ”‚    â”‚ - User      â”‚    â”‚ - Bottom  â”‚ â”‚
â”‚                     â”‚   scoring   â”‚    â”‚   response  â”‚    â”‚   line    â”‚ â”‚
â”‚                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                           â”‚
â”‚  Confidence Thresholds:                                                   â”‚
â”‚  - â‰¥90%: Proceed automatically                                           â”‚
â”‚  - 70-89%: Note uncertainty, proceed                                     â”‚
â”‚  - 50-69%: Ask clarifying question                                       â”‚
â”‚  - <50%: Require user input                                              â”‚
â”‚                                                                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 5.6 Browser Visualization Architecture

```typescript
// src/canvases/analytics/browser/index.ts
interface BrowserViz {
  // Chart generation
  createChart(config: ChartConfig): HTMLString;
  createDashboard(charts: ChartConfig[]): HTMLString;

  // Interactivity
  addFilter(chart: Chart, filter: FilterConfig): void;
  addDrilldown(chart: Chart, handler: DrilldownHandler): void;

  // Export
  exportPNG(chart: Chart): Promise<Buffer>;
  exportSVG(chart: Chart): string;

  // Server
  serve(port: number): Promise<void>;  // Local server for live updates
  open(): Promise<void>;  // Open in default browser
}
```

### 5.7 IPC Message Extensions

New messages for interactive features:

```typescript
// Controller â†’ Canvas
| { type: "filter"; column: string; condition: FilterCondition }
| { type: "drilldown"; target: DrilldownTarget }
| { type: "changeChart"; chartId: string; newType: ChartType }
| { type: "export"; format: "png" | "svg" | "csv" | "json" }

// Canvas â†’ Controller
| { type: "filterApplied"; resultCount: number }
| { type: "drilldownData"; data: DataPoint[] }
| { type: "exported"; path: string }
| { type: "userQuestion"; question: string }  // Canvas asks Claude
```

---

## 6. User Experience Flows

### 6.1 First-Time Use

```
User: /kowalski

Kowalski:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  KOWALSKI ANALYTICS - MISSION BRIEFING                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Greetings, Skipper. Kowalski reporting for duty.               â”‚
â”‚                                                                  â”‚
â”‚  I'm your data analysis specialist, trained at Stanford         â”‚
â”‚  with expertise in statistical analysis, pattern                â”‚
â”‚  recognition, and hypothesis testing.                            â”‚
â”‚                                                                  â”‚
â”‚  ğŸ“ Recon sweep complete:                                       â”‚
â”‚     â€¢ sales_q4.csv (2,847 rows) - NEW                           â”‚
â”‚     â€¢ customers.json (412 records) - NEW                        â”‚
â”‚                                                                  â”‚
â”‚  ğŸ§  Memory banks: Empty (first mission in this sector)          â”‚
â”‚                                                                  â”‚
â”‚  Awaiting orders, Skipper. What shall I analyze?                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 6.2 Analysis with Uncertainty

```
User: /kowalski analyze sales_q4.csv

Kowalski:
Loading data... scanning 2,847 rows across 8 columns.

âš ï¸ ATTENTION SKIPPER - I need clarification:

Column 'stat' contains values: 1, 2, 3, 4
â†’ 68% confidence these are status codes
â†’ But could also be: rating, priority, category

What does 'stat' represent?
  [1] Status codes (pending/processing/done/cancelled)
  [2] Rating (1-4 scale)
  [3] Priority level
  [4] Something else (please explain)
```

### 6.3 Relationship Discovery

```
User: /kowalski compare sales.csv orders.csv

Kowalski:
Analyzing relationship topology between datasets...

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  RELATIONSHIP INTEL                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  sales.csv â”€â”€â”€â”€[order_id]â”€â”€â”€â”€â–¶ orders.csv                       â”‚
â”‚     2,847 rows                   1,203 rows                      â”‚
â”‚                                                                  â”‚
â”‚  Match Analysis:                                                 â”‚
â”‚  â€¢ 2,412 sales records have matching orders (84.7%)             â”‚
â”‚  â€¢ 435 orphan sales records (no matching order)                 â”‚
â”‚  â€¢ Relationship: Many-to-One (multiple sales per order)         â”‚
â”‚                                                                  â”‚
â”‚  Confidence: 94%                                                 â”‚
â”‚                                                                  â”‚
â”‚  âš ï¸ Data quality note:                                          â”‚
â”‚  435 orphan records is unusual (15.3%). Possible causes:        â”‚
â”‚  1. Orders deleted but sales retained                            â”‚
â”‚  2. Data export timing mismatch                                  â”‚
â”‚  3. Test/demo data mixed with production                         â”‚
â”‚                                                                  â”‚
â”‚  Shall I investigate the orphan records, Skipper?               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 6.4 Hypothesis Generation

```
Kowalski:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  HYPOTHESIS BRIEFING                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  Based on preliminary analysis, I've generated testable         â”‚
â”‚  hypotheses:                                                     â”‚
â”‚                                                                  â”‚
â”‚  H1: Marketing spend drives revenue                              â”‚
â”‚      Evidence: r=0.87 correlation                                â”‚
â”‚      Confidence: 91%                                             â”‚
â”‚      Caution: Correlation â‰  causation. Confounders:             â”‚
â”‚               - Seasonality (both spike in Q4)                  â”‚
â”‚               - Company growth trend                             â”‚
â”‚                                                                  â”‚
â”‚  H2: Customer segment affects order value                        â”‚
â”‚      Evidence: Enterprise avg $2,340 vs SMB avg $890            â”‚
â”‚      Confidence: 88%                                             â”‚
â”‚      Statistical test: t-test p < 0.001                         â”‚
â”‚                                                                  â”‚
â”‚  H3: Delivery time impacts return rate                           â”‚
â”‚      Evidence: Weak negative correlation (r=-0.23)              â”‚
â”‚      Confidence: 62%                                             â”‚
â”‚      Recommendation: Needs more data to confirm                 â”‚
â”‚                                                                  â”‚
â”‚  Which hypothesis shall we investigate further, Skipper?        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 7. File Structure

```
src/
â”œâ”€â”€ skills/
â”‚   â””â”€â”€ kowalski/
â”‚       â”œâ”€â”€ index.ts              # Skill registration
â”‚       â”œâ”€â”€ handler.ts            # Command handler
â”‚       â”œâ”€â”€ commands/
â”‚       â”‚   â”œâ”€â”€ analyze.ts        # /kowalski analyze
â”‚       â”‚   â”œâ”€â”€ compare.ts        # /kowalski compare
â”‚       â”‚   â”œâ”€â”€ query.ts          # /kowalski query (MCP/API)
â”‚       â”‚   â”œâ”€â”€ memory.ts         # /kowalski memory
â”‚       â”‚   â””â”€â”€ dashboard.ts      # /kowalski dashboard
â”‚       â””â”€â”€ personality.ts        # Kowalski voice/messaging
â”‚
â”œâ”€â”€ canvases/
â”‚   â””â”€â”€ analytics/
â”‚       â”œâ”€â”€ brain.ts              # NEW: Analysis brain
â”‚       â”œâ”€â”€ understanding.ts      # NEW: Data understanding
â”‚       â”œâ”€â”€ memory.ts             # NEW: Memory manager
â”‚       â”œâ”€â”€ hypotheses.ts         # NEW: Hypothesis engine
â”‚       â”œâ”€â”€ relationships.ts      # NEW: Relationship discovery
â”‚       â”œâ”€â”€ confidence.ts         # NEW: Confidence scoring
â”‚       â”œâ”€â”€ questions.ts          # NEW: Clarifying questions
â”‚       â”‚
â”‚       â”œâ”€â”€ browser/              # NEW: Browser viz
â”‚       â”‚   â”œâ”€â”€ index.ts
â”‚       â”‚   â”œâ”€â”€ server.ts         # Local viz server
â”‚       â”‚   â”œâ”€â”€ charts.tsx        # Recharts components
â”‚       â”‚   â”œâ”€â”€ dashboard.tsx     # Full dashboard
â”‚       â”‚   â””â”€â”€ export.ts         # PNG/SVG export
â”‚       â”‚
â”‚       â”œâ”€â”€ components/           # EXISTING: Terminal viz
â”‚       â”‚   â”œâ”€â”€ eda-dashboard.tsx # Enhanced with interactions
â”‚       â”‚   â”œâ”€â”€ filter-panel.tsx  # NEW: Filter UI
â”‚       â”‚   â””â”€â”€ ...
â”‚       â”‚
â”‚       â”œâ”€â”€ data-loader.ts        # EXISTING: Enhanced
â”‚       â”œâ”€â”€ stats.ts              # EXISTING: Enhanced
â”‚       â”œâ”€â”€ insights.ts           # EXISTING: Enhanced
â”‚       â””â”€â”€ types.ts              # EXISTING: Extended
â”‚
â””â”€â”€ ipc/
    â””â”€â”€ types.ts                  # Extended with new messages
```

---

## 8. Dependencies

### 8.1 Existing (No Changes)
- `ink` - Terminal UI framework
- `react` - Component rendering
- `chalk` - Terminal colors

### 8.2 New Dependencies
- `recharts` - Browser chart library
- `express` - Local viz server (minimal)
- `open` - Open browser automatically
- `html-to-image` - PNG export (optional, can use canvas)

---

## 9. Testing Strategy

### 9.1 Unit Tests
- Statistical functions (correlation, regression, outlier detection)
- Schema inference accuracy
- Relationship detection
- Memory serialization/deserialization

### 9.2 Integration Tests
- End-to-end analysis pipeline
- IPC communication
- Browser viz rendering
- Export functionality

### 9.3 Test Datasets
- `sample_data/sales.csv` - Clean, well-structured (existing)
- `sample_data/messy_data.csv` - Missing values, mixed types
- `sample_data/synthetic.csv` - For synthetic detection testing
- `sample_data/related_tables/` - Multi-file relationship testing

---

## 10. Success Metrics

### 10.1 Accuracy
- Schema inference: > 90% accuracy on standard datasets
- Relationship detection: > 85% accuracy on joined tables
- Synthetic data detection: > 95% true positive rate

### 10.2 User Experience
- Time to first insight: < 10 seconds
- Clarifying questions: Relevant and minimal (< 3 per dataset)
- User satisfaction with Kowalski personality: Qualitative feedback

### 10.3 Performance
- Handles 100k row datasets without degradation
- Dashboard interactions < 500ms response time
- Memory footprint < 500MB for large datasets

---

## 11. Future Considerations

### 11.1 Phase 2 (Not in Scope)
- Machine learning model integration (clustering, classification)
- Natural language query interface ("show me revenue by region")
- Collaborative analysis (share findings with team)
- Data transformation pipelines

### 11.2 Phase 3 (Not in Scope)
- Automated report generation (PDF/HTML)
- Scheduled analysis jobs
- Data versioning and lineage
- Integration with BI tools

---

## Appendix A: Reference Implementation Details

### A.1 Existing Infrastructure (from codebase exploration)

| Component | File | Description |
|-----------|------|-------------|
| CSV Parser | `data-loader.ts` | Robust quote handling, type inference |
| Statistics | `stats.ts` | Mean, median, std, correlation, trends |
| Insights | `insights.ts` | EDA report, synthetic detection, findings |
| EDA Dashboard | `eda-dashboard.tsx` | Two-column Ink layout |
| Braille Charts | `braille-charts.tsx` | High-res terminal charts |
| Canvas Spawn | `canvas-api.ts` | IPC server, tmux integration |
| Terminal Mgmt | `terminal.ts` | Tmux split, app detection |
| IPC Types | `ipc/types.ts` | Message definitions |

### A.2 Key Interfaces to Extend

```typescript
// Extend AnalysisResult
interface AnalysisResult {
  // ... existing
  hypotheses?: Hypothesis[];
  relationships?: Relationship[];
  confidenceScores?: Map<string, number>;
}

// Extend EDAReport
interface EDAReport {
  // ... existing
  clarifyingQuestions?: Question[];
  uncertainties?: Uncertainty[];
}
```

---

*Document Version: 1.0*
*Last Updated: 2026-01-13*
*Author: Kowalski Analytics Team*
